{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Stream Directory Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the first part of the exercise, you will create a simple Spark streaming program that reads an input stream from a file source. The file source stream reader reads data from a directory on a file system. When a new file is added to the folder, Spark adds that fileâ€™s data to the input data stream.\n",
    "\n",
    "You can find the input data for this exercise in the baby-names/streaming directory. This directory contains the baby names CSV file randomized and split into 98 individual files. You will use these files to simulate incoming streaming data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Count the Number of Females\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of the exercise, you will create a Spark program that monitors an incoming directory. To simulate streaming data, you will copy CSV files from the baby-names/streaming directory into the incoming directory. Since you will be loading CSV data, you will need to define a schema before you initialize the streaming dataframe.\n",
    "\n",
    "From this input data stream, you will create a simple output data stream that counts the number of females and writes it to the console. Approximately every 10 seconds or so, copy a new file into the directory and report the console output. Do this for the first ten files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "import shutil \n",
    "from time import sleep\n",
    "import os.path \n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file paths including filenames\n",
    "file_path = r'/home/ram/share/650/dsc650-master/data/baby-names/streaming'\n",
    "\n",
    "ipstreaming_file_path = r'/home/ram/Documents/650/input_streaming'\n",
    "\n",
    "batchstream_file_path = r'/home/ram/Documents/650/batch_streaming'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('week8') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "static = spark.read.csv(file_path, header = True)\n",
    "dataschema = static.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(state='CO', sex='F', year='2014', name='Aubriana', count='8'),\n",
       " Row(state='AR', sex='F', year='1975', name='Patricia', count='61'),\n",
       " Row(state='IN', sex='F', year='1959', name='Bethany', count='7'),\n",
       " Row(state='MI', sex='F', year='2007', name='Lilyan', count='5'),\n",
       " Row(state='IL', sex='M', year='1979', name='Garrett', count='47')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5880000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static.count()\n",
    "#5880000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(static))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading stream from input directory\n",
    "streaming = spark.readStream.schema(dataschema).csv(ipstreaming_file_path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.option(\"maxFilesPerTrigger\", 1)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[sex: string, count: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = streaming.groupBy(\"sex\").count()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counts.select(\"sex\").where(\"sex = 'F'\")\n",
    "counts.groupBy(\"sex\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamingquery.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamingquery = counts.writeStream.queryName(\"counts\")\\\n",
    "                                    .format(\"memory\").outputMode(\"complete\")\\\n",
    "                                    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.streaming.StreamingQuery at 0x7f3bec5e46a0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print active streams\n",
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(static.isStreaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|33417|\n",
      "|  M|26583|\n",
      "|sex|    1|\n",
      "+---+-----+\n",
      "\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|33417|\n",
      "|  M|26583|\n",
      "|sex|    1|\n",
      "+---+-----+\n",
      "\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|33417|\n",
      "|  M|26583|\n",
      "|sex|    1|\n",
      "+---+-----+\n",
      "\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|33417|\n",
      "|  M|26583|\n",
      "|sex|    1|\n",
      "+---+-----+\n",
      "\n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|33417|\n",
      "|  M|26583|\n",
      "|sex|    1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "for x in range(5):\n",
    "    spark.sql(\"SELECT * FROM counts\").show()\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['names_01.csv', 'names_02.csv', 'names_03.csv', 'names_04.csv', 'names_05.csv', 'names_06.csv', 'names_07.csv', 'names_08.csv', 'names_09.csv', 'names_10.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fileslist = os.listdir(file_path)\n",
    "print(fileslist[1:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ram/share/650/dsc650-master/data/baby-names/streaming/names_04.csv /home/ram/Documents/650/input_streaming/names_04.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "src_path = os.path.join(file_path,fileslist[4])\n",
    "\n",
    "dest_path = os.path.join(ipstreaming_file_path,fileslist[4])\n",
    "\n",
    "print(src_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names_00.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "+---+-----+\n",
      "\n",
      "names_01.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|33417|\n",
      "|  M|26583|\n",
      "|sex|    1|\n",
      "+---+-----+\n",
      "\n",
      "names_02.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|67008|\n",
      "|  M|52992|\n",
      "|sex|    2|\n",
      "+---+-----+\n",
      "\n",
      "names_03.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|100361|\n",
      "|  M| 79639|\n",
      "|sex|     3|\n",
      "+---+------+\n",
      "\n",
      "names_04.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|133784|\n",
      "|  M|106216|\n",
      "|sex|     4|\n",
      "+---+------+\n",
      "\n",
      "names_05.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|167264|\n",
      "|  M|132736|\n",
      "|sex|     5|\n",
      "+---+------+\n",
      "\n",
      "names_06.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|200789|\n",
      "|  M|159211|\n",
      "|sex|     6|\n",
      "+---+------+\n",
      "\n",
      "names_07.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|234184|\n",
      "|  M|185816|\n",
      "|sex|     7|\n",
      "+---+------+\n",
      "\n",
      "names_08.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|267752|\n",
      "|  M|212248|\n",
      "|sex|     8|\n",
      "+---+------+\n",
      "\n",
      "names_09.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|301272|\n",
      "|  M|238728|\n",
      "|sex|     9|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fileslist[1:11])):\n",
    "    \n",
    "    file = fileslist[i]\n",
    "    \n",
    "    print(file)\n",
    "    src_path = os.path.join(file_path,file)\n",
    "    dest_path = os.path.join(ipstreaming_file_path,file)\n",
    "    \n",
    "    shutil.copy(src_path, dest_path) \n",
    "    print(\"Moved the file \\n\")\n",
    "    \n",
    "    \n",
    "    print(\"Lets check the counts \\n \")\n",
    "    sleep(2)\n",
    "    spark.sql(\"SELECT * FROM counts\").show()\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Micro-Batching\n",
    "\n",
    "Repeat the last step, but use a micro-batch interval to trigger the processing every 30 seconds. Approximately every 10 seconds or so, copy a new file into the directory and report the console output. Do this for the first ten files. How did the output differ from the previous example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[sex: string, count: bigint]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading stream from input directory\n",
    "csvdf = spark.readStream.schema(dataschema).csv(batchstream_file_path)  \n",
    "\n",
    "batch_counts = csvdf.groupBy(\"sex\").count()\n",
    "\n",
    "#select count of females\n",
    "\n",
    "batch_counts.select(\"sex\").where(\"sex = 'F'\")\n",
    "\n",
    "batch_counts.groupby(\"sex\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#microbatch_counts = csvdf.groupBy(window(\"30 seconds\"), csvdf.sex).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "microbatch_writer = batch_counts.writeStream.trigger(processingTime = '30 seconds').queryName(\"batch_counts\")\\\n",
    "                                    .format(\"memory\").outputMode(\"complete\")\\\n",
    "                                    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microbatch_writer.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names_00.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|33417|\n",
      "|  M|26583|\n",
      "|sex|    1|\n",
      "+---+-----+\n",
      "\n",
      "names_01.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|33417|\n",
      "|  M|26583|\n",
      "|sex|    1|\n",
      "+---+-----+\n",
      "\n",
      "names_02.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|33417|\n",
      "|  M|26583|\n",
      "|sex|    1|\n",
      "+---+-----+\n",
      "\n",
      "names_03.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+-----+\n",
      "|sex|count|\n",
      "+---+-----+\n",
      "|  F|33417|\n",
      "|  M|26583|\n",
      "|sex|    1|\n",
      "+---+-----+\n",
      "\n",
      "names_04.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|133784|\n",
      "|  M|106216|\n",
      "|sex|     4|\n",
      "+---+------+\n",
      "\n",
      "names_05.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|133784|\n",
      "|  M|106216|\n",
      "|sex|     4|\n",
      "+---+------+\n",
      "\n",
      "names_06.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|133784|\n",
      "|  M|106216|\n",
      "|sex|     4|\n",
      "+---+------+\n",
      "\n",
      "names_07.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|200789|\n",
      "|  M|159211|\n",
      "|sex|     6|\n",
      "+---+------+\n",
      "\n",
      "names_08.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|200789|\n",
      "|  M|159211|\n",
      "|sex|     6|\n",
      "+---+------+\n",
      "\n",
      "names_09.csv\n",
      "Moved the file \n",
      "\n",
      "Lets check the counts \n",
      " \n",
      "+---+------+\n",
      "|sex| count|\n",
      "+---+------+\n",
      "|  F|301272|\n",
      "|  M|238728|\n",
      "|sex|     9|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fileslist[1:11])):\n",
    "    \n",
    "    file = fileslist[i]\n",
    "    \n",
    "    print(file)\n",
    "    src_path = os.path.join(file_path,file)\n",
    "    dest_path = os.path.join(batchstream_file_path,file)\n",
    "    \n",
    "    shutil.copy(src_path, dest_path) \n",
    "    print(\"Moved the file \\n\")\n",
    "    \n",
    "    \n",
    "    print(\"Lets check the counts \\n \")\n",
    "    sleep(1)\n",
    "    spark.sql(\"SELECT * FROM batch_counts\").show()\n",
    "    sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
